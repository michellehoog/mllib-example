{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cce98b8f05b1:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Classification</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4e10cc5ac0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"Classification\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, MinMaxScaler, OneHotEncoder, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>resting_bps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fast_blood_sugar</th>\n",
       "      <th>rest_ecg_type</th>\n",
       "      <th>max_hr</th>\n",
       "      <th>exercise_angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope_type</th>\n",
       "      <th>colored_arteries</th>\n",
       "      <th>thal_type</th>\n",
       "      <th>heart_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  chest_pain_type  resting_bps   chol  fast_blood_sugar  \\\n",
       "0  63.0  1.0              1.0        145.0  233.0               1.0   \n",
       "1  67.0  1.0              4.0        160.0  286.0               0.0   \n",
       "2  67.0  1.0              4.0        120.0  229.0               0.0   \n",
       "3  37.0  1.0              3.0        130.0  250.0               0.0   \n",
       "4  41.0  0.0              2.0        130.0  204.0               0.0   \n",
       "5  56.0  1.0              2.0        120.0  236.0               0.0   \n",
       "\n",
       "   rest_ecg_type  max_hr  exercise_angina  oldpeak  slope_type  \\\n",
       "0            2.0   150.0              0.0      2.3         3.0   \n",
       "1            2.0   108.0              1.0      1.5         2.0   \n",
       "2            2.0   129.0              1.0      2.6         2.0   \n",
       "3            0.0   187.0              0.0      3.5         3.0   \n",
       "4            2.0   172.0              0.0      1.4         1.0   \n",
       "5            0.0   178.0              0.0      0.8         1.0   \n",
       "\n",
       "   colored_arteries  thal_type  heart_disease  \n",
       "0               0.0        6.0              0  \n",
       "1               3.0        3.0              2  \n",
       "2               2.0        7.0              1  \n",
       "3               0.0        3.0              0  \n",
       "4               0.0        3.0              0  \n",
       "5               0.0        3.0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define field names and types\n",
    "schema = StructType([\n",
    "    StructField(\"age\", FloatType(), True),\n",
    "    StructField(\"sex\", FloatType(), True),\n",
    "    StructField(\"chest_pain_type\", FloatType(), True),\n",
    "    StructField(\"resting_bps\", FloatType(), True),\n",
    "    StructField(\"chol\", FloatType(), True),\n",
    "    StructField(\"fast_blood_sugar\", FloatType(), True),\n",
    "    StructField(\"rest_ecg_type\", FloatType(), True),\n",
    "    StructField(\"max_hr\", FloatType(), True),\n",
    "    StructField(\"exercise_angina\", FloatType(), True),\n",
    "    StructField(\"oldpeak\", FloatType(), True),\n",
    "    StructField(\"slope_type\", FloatType(), True),\n",
    "    StructField(\"colored_arteries\", FloatType(), True),\n",
    "    StructField(\"thal_type\", FloatType(), True),\n",
    "    StructField(\"heart_disease\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "df = spark.read.csv(\"data/processed.cleveland.data\", schema = schema, header = False, nullValue=\"?\")\n",
    "df.limit(6).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  summary                age                  sex     chest_pain_type  \\\n",
      "0   count                303                  303                 303   \n",
      "1    mean  54.43894389438944   0.6798679867986799  3.1584158415841586   \n",
      "2  stddev   9.03866244244675  0.46729882777012977  0.9601256119600138   \n",
      "3     min               29.0                  0.0                 1.0   \n",
      "4     max               77.0                  1.0                 4.0   \n",
      "\n",
      "          resting_bps                chol    fast_blood_sugar  \\\n",
      "0                 303                 303                 303   \n",
      "1  131.68976897689768  246.69306930693068  0.1485148514851485   \n",
      "2   17.59974772958769  51.776917542637065  0.3561978749279763   \n",
      "3                94.0               126.0                 0.0   \n",
      "4               200.0               564.0                 1.0   \n",
      "\n",
      "        rest_ecg_type              max_hr      exercise_angina  \\\n",
      "0                 303                 303                  303   \n",
      "1  0.9900990099009901   149.6072607260726  0.32673267326732675   \n",
      "2  0.9949712915251783  22.875003276980383  0.46979446452231644   \n",
      "3                 0.0                71.0                  0.0   \n",
      "4                 2.0               202.0                  1.0   \n",
      "\n",
      "              oldpeak          slope_type    colored_arteries  \\\n",
      "0                 303                 303                 299   \n",
      "1  1.0396039587977302  1.6006600660066006  0.6722408026755853   \n",
      "2  1.1610750102689422  0.6162261453459619   0.937438317724216   \n",
      "3                 0.0                 1.0                 0.0   \n",
      "4                 6.2                 3.0                 3.0   \n",
      "\n",
      "            thal_type       heart_disease  \n",
      "0                 301                 303  \n",
      "1    4.73421926910299  0.9372937293729373  \n",
      "2  1.9397057693786433  1.2285356879701044  \n",
      "3                 3.0                   0  \n",
      "4                 7.0                   4  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe().toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|heart_disease|count|\n",
      "+-------------+-----+\n",
      "|            1|   55|\n",
      "|            3|   35|\n",
      "|            4|   13|\n",
      "|            2|   36|\n",
      "|            0|  164|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"heart_disease\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  chest_pain_type  resting_bps  chol  fast_blood_sugar  \\\n",
      "0    0    0                0            0     0                 0   \n",
      "\n",
      "   rest_ecg_type  max_hr  exercise_angina  oldpeak  slope_type  \\\n",
      "0              0       0                0        0           0   \n",
      "\n",
      "   colored_arteries  thal_type  heart_disease  \n",
      "0                 4          2              0  \n"
     ]
    }
   ],
   "source": [
    "#check how much missing data there is\n",
    "dataAgg = df.agg(*[count(when(isnull(c), c)).alias(c) for c in df.columns])\n",
    "print(dataAgg.limit(8).toPandas())\n",
    "\n",
    "dfClean = df.na.drop()\n",
    "features = df.columns[:-1]\n",
    "label = \"heart_disease\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|  137|\n",
      "|    0|  160|\n",
      "+-----+-----+\n",
      "\n",
      "None\n",
      "['chest_pain_type', 'rest_ecg_type', 'slope_type', 'thal_type']\n"
     ]
    }
   ],
   "source": [
    "# change from multiclass to binary prediction\n",
    "dfBinary = dfClean.withColumn(\"label\", when(dfClean.heart_disease == 0, 0).otherwise(1))\n",
    "print(dfBinary.groupBy(\"label\").count().show())\n",
    "\n",
    "#categorical cols will be indexed later\n",
    "categoricalCols = [col for col in dfBinary.columns if \"type\" in col]\n",
    "print(categoricalCols)\n",
    "\n",
    "continuousCols = [f for f in features if \"type\" not in f]\n",
    "continuousCols.remove(\"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.7083333333333333, 0.4811320754716981, 0.244...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.7916666666666666, 0.6226415094339622, 0.365...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.7916666666666666, 0.24528301886792453, 0.23...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.16666666666666666, 0.33962264150943394, 0.2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.25, 0.33962264150943394, 0.1780821917808219...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.5625, 0.24528301886792453, 0.25114155251141...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.6875, 0.43396226415094336, 0.32420091324200...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.5833333333333333, 0.24528301886792453, 0.52...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.7083333333333333, 0.33962264150943394, 0.29...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.5, 0.43396226415094336, 0.17579908675799086...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  label\n",
       "0  [0.7083333333333333, 0.4811320754716981, 0.244...      0\n",
       "1  [0.7916666666666666, 0.6226415094339622, 0.365...      1\n",
       "2  [0.7916666666666666, 0.24528301886792453, 0.23...      1\n",
       "3  [0.16666666666666666, 0.33962264150943394, 0.2...      0\n",
       "4  [0.25, 0.33962264150943394, 0.1780821917808219...      0\n",
       "5  (0.5625, 0.24528301886792453, 0.25114155251141...      0\n",
       "6  [0.6875, 0.43396226415094336, 0.32420091324200...      1\n",
       "7  [0.5833333333333333, 0.24528301886792453, 0.52...      0\n",
       "8  [0.7083333333333333, 0.33962264150943394, 0.29...      1\n",
       "9  [0.5, 0.43396226415094336, 0.17579908675799086...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dense feature vector and scale\n",
    "featuresList = continuousCols + categoricalCols\n",
    "\n",
    "assembler = VectorAssembler(inputCols = featuresList, outputCol = \"features\")\n",
    "indexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexed\", maxCategories=5)\n",
    "scaler = MinMaxScaler(inputCol=\"indexed\", outputCol=\"features_scaled\")\n",
    "pipeline = Pipeline(stages=[assembler, indexer, scaler])\n",
    "scalerModel = pipeline.fit(dfBinary)\n",
    "scaledData = scalerModel.transform(dfBinary).select(\"features_scaled\", \"label\")\n",
    "scaledData = scaledData.withColumnRenamed(\"features_scaled\", \"features\")\n",
    "scaledData.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 212, test len: 85\n"
     ]
    }
   ],
   "source": [
    "train, test = scaledData.randomSplit([0.7, 0.3])\n",
    "print(f\"train len: {train.count()}, test len: {test.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Area under ROC: 0.903153153153153\n",
      "GBTClassifier\n",
      "Area under ROC: 0.8006756756756754\n",
      "RandomForestClassifier\n",
      "Area under ROC: 0.902027027027027\n"
     ]
    }
   ],
   "source": [
    "def selectParameters(Mtype):\n",
    "    if Mtype == \"LogisticRegression\":\n",
    "            paramGrid = (ParamGridBuilder() \\\n",
    "#                          .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                         .addGrid(classifier.maxIter, [10, 15,20])\n",
    "                         .build())\n",
    "    if Mtype == \"RandomForestClassifier\":\n",
    "            paramGrid = (ParamGridBuilder() \\\n",
    "#                          .addGrid(classifier.maxDepth, [2, 5, 10]) \\\n",
    "#                          .addGrid(classifier.maxBins, [5, 10, 20]) \\\n",
    "                         .addGrid(classifier.numTrees, [5, 20])\n",
    "                         .build())\n",
    "\n",
    "    if Mtype == \"GBTClassifier\":\n",
    "        paramGrid = (ParamGridBuilder() \\\n",
    "#                      .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "#                      .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "#                      .addGrid(classifier.maxIter, [10, 15]) \\\n",
    "                     .addGrid(classifier.stepSize, [0.1, 0.2, 0.3]) #learning rate\n",
    "                     .build())\n",
    "    return paramGrid\n",
    "\n",
    "                \n",
    "classifiers = [LogisticRegression(), GBTClassifier(), RandomForestClassifier()]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    \n",
    "    Mtype = type(classifier).__name__\n",
    "    print(Mtype)\n",
    "    BCEvaluator = BinaryClassificationEvaluator() \n",
    "    paramGrid = selectParameters(Mtype)\n",
    "\n",
    "    crossval = CrossValidator(\n",
    "        estimator = classifier,\n",
    "        estimatorParamMaps = paramGrid,\n",
    "        evaluator=BCEvaluator,\n",
    "        numFolds= 2)\n",
    "\n",
    "    fitModel = crossval.fit(train)\n",
    "\n",
    "    best_model = fitModel.bestModel\n",
    "    predictions = fitModel.transform(test) #fitModel automatically uses best model\n",
    "    areaUnderROC = BCEvaluator.evaluate(predictions)\n",
    "    print(f\"Area under ROC: {areaUnderROC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "For models such as logistic regression you can also get model summary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|FPR| TPR|\n",
      "+---+----+\n",
      "|0.0| 0.0|\n",
      "|0.0|0.02|\n",
      "|0.0|0.04|\n",
      "|0.0|0.06|\n",
      "|0.0|0.08|\n",
      "|0.0| 0.1|\n",
      "|0.0|0.12|\n",
      "|0.0|0.14|\n",
      "|0.0|0.16|\n",
      "|0.0|0.18|\n",
      "+---+----+\n",
      "\n",
      "Coefficients: \n",
      "DenseMatrix([[-2.83419255,  2.42154978,  0.89220182, -0.1533292 , -4.57204062,\n",
      "               0.98464082,  1.41579521,  4.02179428,  1.43571494,  0.34894122,\n",
      "               0.78117619,  2.39696765]])\n",
      "Intercept: [-0.7665040236657693]\n",
      "areaUnderROC: 0.91625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression_8c72198e5432"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification diagnostics for logistic regression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "crossval = CrossValidator(\n",
    "        estimator = lr,\n",
    "        estimatorParamMaps = paramGrid,\n",
    "        evaluator=BCEvaluator,\n",
    "        numFolds= 2)\n",
    "    \n",
    "lrModel = crossval.fit(train)\n",
    "best_Model = lrModel.bestModel\n",
    "    \n",
    "trainingSummary = best_Model.summary\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.limit(10).show()\n",
    "\n",
    "print(\"Coefficients: \\n\" + str(best_Model.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(best_Model.interceptVector))\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max(\"F-Measure\").select(\"max(F-Measure)\").head()\n",
    "bestThreshold = fMeasure.where(fMeasure[\"F-Measure\"] == maxFMeasure[\"max(F-Measure)\"]) \\\n",
    "    .select(\"threshold\").head()[\"threshold\"]\n",
    "\n",
    "lr.setThreshold(bestThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
