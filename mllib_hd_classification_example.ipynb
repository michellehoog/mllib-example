{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cce98b8f05b1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Classification</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f68e4bf5ac0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"Classification\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, MinMaxScaler, OneHotEncoder, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.set_experiment(experiment_name = \"sd_ml\")\n",
    "\n",
    "# #set up client\n",
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create a run\n",
    "\n",
    "# # Create a run and attach it to the experiment you just created\n",
    "# experiments = client.list_experiments() # returns a list of mlflow.entities.Experiment\n",
    "\n",
    "# experiment_name = \"sd-ml\"\n",
    "# def create_run(experiment_name):\n",
    "#     mlflow.set_experiment(experiment_name = experiment_name)\n",
    "#     for x in experiments:\n",
    "#         if experiment_name in x.name:\n",
    "# #             print(experiment_name)\n",
    "# #             print(x)\n",
    "#             experiment_index = experiments.index(x)\n",
    "#             run = client.create_run(experiments[experiment_index].experiment_id) # returns mlflow.entities.Run\n",
    "# #             print(run)\n",
    "#             return run\n",
    "\n",
    "# # Example run command\n",
    "# # run = create_run('Experiment-3')\n",
    "# # run = create_run(experiment_name)\n",
    "# # add tags to run\n",
    "# # add params and metrics to a run\n",
    "# # #terminate client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test the functionality here\n",
    "# run = create_run('sd-ml')\n",
    "\n",
    "# # Add tag to a run\n",
    "# client.set_tag(run.info.run_id, \"Algorithm\", \"Gradient Boosted Tree\")\n",
    "# client.set_tag(run.info.run_id,\"Random Seed\",999)\n",
    "# client.set_tag(run.info.run_id,\"Train Perct\",999)\n",
    "\n",
    "# # Add params and metrics to a run\n",
    "# client.log_param(run.info.run_id, \"Max Depth\", 999)\n",
    "# client.log_param(run.info.run_id, \"Max Bins\", 999)\n",
    "# client.log_metric(run.info.run_id, \"Accuracy\", 999)\n",
    "\n",
    "# # Terminate the client\n",
    "# client.set_terminated(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>resting_bps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fast_blood_sugar</th>\n",
       "      <th>rest_ecg_type</th>\n",
       "      <th>max_hr</th>\n",
       "      <th>exercise_angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope_type</th>\n",
       "      <th>colored_arteries</th>\n",
       "      <th>thal_type</th>\n",
       "      <th>heart_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  chest_pain_type  resting_bps   chol  fast_blood_sugar  \\\n",
       "0  63.0  1.0              1.0        145.0  233.0               1.0   \n",
       "1  67.0  1.0              4.0        160.0  286.0               0.0   \n",
       "2  67.0  1.0              4.0        120.0  229.0               0.0   \n",
       "3  37.0  1.0              3.0        130.0  250.0               0.0   \n",
       "4  41.0  0.0              2.0        130.0  204.0               0.0   \n",
       "5  56.0  1.0              2.0        120.0  236.0               0.0   \n",
       "\n",
       "   rest_ecg_type  max_hr  exercise_angina  oldpeak  slope_type  \\\n",
       "0            2.0   150.0              0.0      2.3         3.0   \n",
       "1            2.0   108.0              1.0      1.5         2.0   \n",
       "2            2.0   129.0              1.0      2.6         2.0   \n",
       "3            0.0   187.0              0.0      3.5         3.0   \n",
       "4            2.0   172.0              0.0      1.4         1.0   \n",
       "5            0.0   178.0              0.0      0.8         1.0   \n",
       "\n",
       "   colored_arteries  thal_type  heart_disease  \n",
       "0               0.0        6.0              0  \n",
       "1               3.0        3.0              2  \n",
       "2               2.0        7.0              1  \n",
       "3               0.0        3.0              0  \n",
       "4               0.0        3.0              0  \n",
       "5               0.0        3.0              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"age\", FloatType(), True),\n",
    "    StructField(\"sex\", FloatType(), True),\n",
    "    StructField(\"chest_pain_type\", FloatType(), True),\n",
    "    StructField(\"resting_bps\", FloatType(), True),\n",
    "    StructField(\"chol\", FloatType(), True),\n",
    "    StructField(\"fast_blood_sugar\", FloatType(), True),\n",
    "    StructField(\"rest_ecg_type\", FloatType(), True),\n",
    "    StructField(\"max_hr\", FloatType(), True),\n",
    "    StructField(\"exercise_angina\", FloatType(), True),\n",
    "    StructField(\"oldpeak\", FloatType(), True),\n",
    "    StructField(\"slope_type\", FloatType(), True),\n",
    "    StructField(\"colored_arteries\", FloatType(), True),\n",
    "    StructField(\"thal_type\", FloatType(), True),\n",
    "    StructField(\"heart_disease\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "df = spark.read.csv(\"data/processed.cleveland.data\", schema = schema, header = False, nullValue='?')\n",
    "df.limit(6).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  summary                age                  sex     chest_pain_type  \\\n",
      "0   count                303                  303                 303   \n",
      "1    mean  54.43894389438944   0.6798679867986799  3.1584158415841586   \n",
      "2  stddev   9.03866244244675  0.46729882777012977  0.9601256119600138   \n",
      "3     min               29.0                  0.0                 1.0   \n",
      "4     max               77.0                  1.0                 4.0   \n",
      "\n",
      "          resting_bps                chol    fast_blood_sugar  \\\n",
      "0                 303                 303                 303   \n",
      "1  131.68976897689768  246.69306930693068  0.1485148514851485   \n",
      "2   17.59974772958769  51.776917542637065  0.3561978749279763   \n",
      "3                94.0               126.0                 0.0   \n",
      "4               200.0               564.0                 1.0   \n",
      "\n",
      "        rest_ecg_type              max_hr      exercise_angina  \\\n",
      "0                 303                 303                  303   \n",
      "1  0.9900990099009901   149.6072607260726  0.32673267326732675   \n",
      "2  0.9949712915251783  22.875003276980383  0.46979446452231644   \n",
      "3                 0.0                71.0                  0.0   \n",
      "4                 2.0               202.0                  1.0   \n",
      "\n",
      "              oldpeak          slope_type    colored_arteries  \\\n",
      "0                 303                 303                 299   \n",
      "1  1.0396039587977302  1.6006600660066006  0.6722408026755853   \n",
      "2  1.1610750102689422  0.6162261453459619   0.937438317724216   \n",
      "3                 0.0                 1.0                 0.0   \n",
      "4                 6.2                 3.0                 3.0   \n",
      "\n",
      "            thal_type       heart_disease  \n",
      "0                 301                 303  \n",
      "1    4.73421926910299  0.9372937293729373  \n",
      "2  1.9397057693786433  1.2285356879701044  \n",
      "3                 3.0                   0  \n",
      "4                 7.0                   4  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe().toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|heart_disease|count|\n",
      "+-------------+-----+\n",
      "|            1|   55|\n",
      "|            3|   35|\n",
      "|            4|   13|\n",
      "|            2|   36|\n",
      "|            0|  164|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('heart_disease').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  chest_pain_type  resting_bps  chol  fast_blood_sugar  \\\n",
      "0    0    0                0            0     0                 0   \n",
      "\n",
      "   rest_ecg_type  max_hr  exercise_angina  oldpeak  slope_type  \\\n",
      "0              0       0                0        0           0   \n",
      "\n",
      "   colored_arteries  thal_type  heart_disease  \n",
      "0                 4          2              0  \n"
     ]
    }
   ],
   "source": [
    "#check how much missing data there is\n",
    "data_agg = df.agg(*[count(when(isnull(c), c)).alias(c) for c in df.columns])\n",
    "print(data_agg.limit(8).toPandas())\n",
    "\n",
    "df_clean = df.na.drop()\n",
    "features = df.columns[:-1]\n",
    "label = 'heart_disease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---------------+-----------+-----+----------------+-------------+------+---------------+-------+----------+----------------+---------+-------------+-----+\n",
      "| age|sex|chest_pain_type|resting_bps| chol|fast_blood_sugar|rest_ecg_type|max_hr|exercise_angina|oldpeak|slope_type|colored_arteries|thal_type|heart_disease|label|\n",
      "+----+---+---------------+-----------+-----+----------------+-------------+------+---------------+-------+----------+----------------+---------+-------------+-----+\n",
      "|63.0|1.0|            1.0|      145.0|233.0|             1.0|          2.0| 150.0|            0.0|    2.3|       3.0|             0.0|      6.0|            0|    0|\n",
      "|67.0|1.0|            4.0|      160.0|286.0|             0.0|          2.0| 108.0|            1.0|    1.5|       2.0|             3.0|      3.0|            2|    1|\n",
      "|67.0|1.0|            4.0|      120.0|229.0|             0.0|          2.0| 129.0|            1.0|    2.6|       2.0|             2.0|      7.0|            1|    1|\n",
      "|37.0|1.0|            3.0|      130.0|250.0|             0.0|          0.0| 187.0|            0.0|    3.5|       3.0|             0.0|      3.0|            0|    0|\n",
      "|41.0|0.0|            2.0|      130.0|204.0|             0.0|          2.0| 172.0|            0.0|    1.4|       1.0|             0.0|      3.0|            0|    0|\n",
      "|56.0|1.0|            2.0|      120.0|236.0|             0.0|          0.0| 178.0|            0.0|    0.8|       1.0|             0.0|      3.0|            0|    0|\n",
      "|62.0|0.0|            4.0|      140.0|268.0|             0.0|          2.0| 160.0|            0.0|    3.6|       3.0|             2.0|      3.0|            3|    1|\n",
      "|57.0|0.0|            4.0|      120.0|354.0|             0.0|          0.0| 163.0|            1.0|    0.6|       1.0|             0.0|      3.0|            0|    0|\n",
      "|63.0|1.0|            4.0|      130.0|254.0|             0.0|          2.0| 147.0|            0.0|    1.4|       2.0|             1.0|      7.0|            2|    1|\n",
      "|53.0|1.0|            4.0|      140.0|203.0|             1.0|          2.0| 155.0|            1.0|    3.1|       3.0|             0.0|      7.0|            1|    1|\n",
      "+----+---+---------------+-----------+-----+----------------+-------------+------+---------------+-------+----------+----------------+---------+-------------+-----+\n",
      "\n",
      "None\n",
      "['chest_pain_type', 'rest_ecg_type', 'slope_type', 'thal_type']\n"
     ]
    }
   ],
   "source": [
    "# change from multiclass to binary prediction\n",
    "df2 = df_clean.withColumn('label', when(df.heart_disease == 0, 0).otherwise(1))\n",
    "print(df2.limit(10).show())\n",
    "\n",
    "categorical_cols = [col for col in df.columns if \"type\" in col]\n",
    "print(categorical_cols)\n",
    "\n",
    "# encoder = OneHotEncoder(\n",
    "#     inputCols=[categorical_cols], \n",
    "#  outputCols=[col + \"_classVec\" for col in categorical_cols]\n",
    "# )\n",
    "\n",
    "continuous_cols = [f for f in features if \"type\" not in f]\n",
    "continuous_cols.remove('sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.7083333333333333, 0.4811320754716981, 0.244...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.7916666666666666, 0.6226415094339622, 0.365...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.7916666666666666, 0.24528301886792453, 0.23...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.16666666666666666, 0.33962264150943394, 0.2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.25, 0.33962264150943394, 0.1780821917808219...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.5625, 0.24528301886792453, 0.25114155251141...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.6875, 0.43396226415094336, 0.32420091324200...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.5833333333333333, 0.24528301886792453, 0.52...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.7083333333333333, 0.33962264150943394, 0.29...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.5, 0.43396226415094336, 0.17579908675799086...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  label\n",
       "0  [0.7083333333333333, 0.4811320754716981, 0.244...      0\n",
       "1  [0.7916666666666666, 0.6226415094339622, 0.365...      1\n",
       "2  [0.7916666666666666, 0.24528301886792453, 0.23...      1\n",
       "3  [0.16666666666666666, 0.33962264150943394, 0.2...      0\n",
       "4  [0.25, 0.33962264150943394, 0.1780821917808219...      0\n",
       "5  (0.5625, 0.24528301886792453, 0.25114155251141...      0\n",
       "6  [0.6875, 0.43396226415094336, 0.32420091324200...      1\n",
       "7  [0.5833333333333333, 0.24528301886792453, 0.52...      0\n",
       "8  [0.7083333333333333, 0.33962264150943394, 0.29...      1\n",
       "9  [0.5, 0.43396226415094336, 0.17579908675799086...      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dense feature vector and scale\n",
    "features_list = continuous_cols + categorical_cols\n",
    "\n",
    "assembler = VectorAssembler(inputCols = features_list, outputCol = 'features')\n",
    "indexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexed\", maxCategories=5)\n",
    "scaler = MinMaxScaler(inputCol=\"indexed\", outputCol=\"features_scaled\")\n",
    "pipeline = Pipeline(stages=[assembler, indexer, scaler])\n",
    "scalerModel = pipeline.fit(df2)\n",
    "scaledData = scalerModel.transform(df2).select('features_scaled', 'label')\n",
    "scaledData = scaledData.withColumnRenamed(\"features_scaled\", \"features\")\n",
    "scaledData.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 202, test len: 95\n"
     ]
    }
   ],
   "source": [
    "train, test = scaledData.randomSplit([0.7, 0.3])\n",
    "print(f\"train len: {train.count()}, test len: {test.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_3a97edd5501f\n",
      "Area under ROC: 0.8872727272727272\n",
      "GBTClassifier_033882483110\n",
      "Area under ROC: 0.8497727272727273\n"
     ]
    }
   ],
   "source": [
    "classifiers = [LogisticRegression(), GBTClassifier()]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    print(classifier)\n",
    "    BC_evaluator = BinaryClassificationEvaluator() \n",
    "\n",
    "    paramGrid = (ParamGridBuilder().addGrid(classifier.maxIter, [10,15,20]).build())\n",
    "\n",
    "    crossval = CrossValidator(\n",
    "        estimator = classifier,\n",
    "        estimatorParamMaps = paramGrid,\n",
    "        evaluator=BC_evaluator,\n",
    "        numFolds= 2)\n",
    "\n",
    "    fitModel = crossval.fit(train)\n",
    "\n",
    "    best_model = fitModel.bestModel\n",
    "    predictions = fitModel.transform(test) #fitModel automatically uses best model\n",
    "    area_under_roc = BC_evaluator.evaluate(predictions)\n",
    "    print(f\"Area under ROC: {area_under_roc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassTrainEval(classifier,features,classes,train,test):\n",
    "\n",
    "    def FindMtype(classifier):\n",
    "        # Intstantiate Model\n",
    "        M = classifier\n",
    "        # Learn what it is\n",
    "        Mtype = type(M).__name__\n",
    "        \n",
    "        return Mtype\n",
    "    \n",
    "    Mtype = FindMtype(classifier)\n",
    "    \n",
    "\n",
    "    def IntanceFitModel(Mtype,classifier,classes,features,train):\n",
    "  \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"LogisticRegression\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,20])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "                               .addGrid(classifier.maxDepth, [2, 5, 10])\n",
    "                               .addGrid(classifier.maxBins, [5, 10, 20])\n",
    "                               .addGrid(classifier.numTrees, [5, 20, 50])\n",
    "                             .build())\n",
    "                \n",
    "            # Add parameters of your choice here:\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "#                              .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                             .addGrid(classifier.maxIter, [10, 15,])\n",
    "                             .build())\n",
    "                \n",
    "            \n",
    "            #Cross Validator requires all of the following parameters:\n",
    "            crossval = CrossValidator(estimator=classifier,\n",
    "                                      estimatorParamMaps=paramGrid,\n",
    "                                      evaluator=BinaryClassificationEvaluator(),\n",
    "                                      numFolds=2) \n",
    "            \n",
    "            # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "            fitModel = crossval.fit(train)\n",
    "            return fitModel\n",
    "    \n",
    "    fitModel = IntanceFitModel(Mtype,classifier,classes,features,train)\n",
    "    \n",
    "    # Print feature selection metrics\n",
    "    if fitModel is not None:\n",
    "        \n",
    "        if Mtype in(\"DecisionTreeClassifier\", \"GBTClassifier\",\"RandomForestClassifier\"):\n",
    "            # FEATURE IMPORTANCES\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Feature Importances\"+ '\\033[0m')\n",
    "            print(\"(Scores add up to 1)\")\n",
    "            print(\"Lowest score is the least important\")\n",
    "            print(\" \")\n",
    "            featureImportances = BestModel.featureImportances.toArray()\n",
    "            print(featureImportances)\n",
    "            \n",
    "            if Mtype in(\"DecisionTreeClassifier\"):\n",
    "                global DT_featureImportances\n",
    "                DT_featureImportances = BestModel.featureImportances.toArray()\n",
    "                global DT_BestModel\n",
    "                DT_BestModel = BestModel\n",
    "            if Mtype in(\"GBTClassifier\"):\n",
    "                global GBT_featureImportances\n",
    "                GBT_featureImportances = BestModel.featureImportances.toArray()\n",
    "                global GBT_BestModel\n",
    "                GBT_BestModel = BestModel\n",
    "            if Mtype in(\"RandomForestClassifier\"):\n",
    "                global RF_featureImportances\n",
    "                RF_featureImportances = BestModel.featureImportances.toArray()\n",
    "                global RF_BestModel\n",
    "                RF_BestModel = BestModel\n",
    "\n",
    "        if Mtype in(\"LogisticRegression\"):\n",
    "            # Get Best Model\n",
    "            BestModel = fitModel.bestModel\n",
    "            print(\" \")\n",
    "            print('\\033[1m' + Mtype,\" Coefficient Matrix\"+ '\\033[0m')\n",
    "            print(\"Coefficients: \\n\" + str(BestModel.coefficientMatrix))\n",
    "            print(\"Intercept: \" + str(BestModel.interceptVector))\n",
    "            global LR_coefficients\n",
    "            LR_coefficients = BestModel.coefficientMatrix.toArray()\n",
    "            global LR_BestModel\n",
    "            LR_BestModel = BestModel\n",
    "        \n",
    "   \n",
    "    # Set the column names to match the external results dataframe that we will join with later:\n",
    "    columns = ['Classifier', 'Result']\n",
    "    \n",
    "\n",
    "    predictions = fitModel.transform(test)\n",
    "    BC_evaluator = BinaryClassificationEvaluator()\n",
    "    area_under_roc = (BC_evaluator.evaluate(predictions))*100\n",
    "    Mtype = [Mtype] # make this a string\n",
    "    score = [str(area_under_roc)] #make this a string and convert to a list\n",
    "    result = spark.createDataFrame(zip(Mtype,score), schema=columns)\n",
    "    result = result.withColumn('Result',result.Result.substr(0, 5))\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mLogisticRegression  Coefficient Matrix\u001b[0m\n",
      "Coefficients: \n",
      "DenseMatrix([[-2.34905609,  2.68676671,  0.469275  , -1.19255681, -5.01377328,\n",
      "               0.5127661 ,  0.3803265 ,  3.24886996,  2.16767596,  0.44014217,\n",
      "               1.18179712,  2.1399278 ]])\n",
      "Intercept: [-1.0639434478486376]\n",
      " \n",
      "\u001b[1mGBTClassifier  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "[0.15647879 0.05654415 0.13557847 0.00040801 0.14525112 0.02227026\n",
      " 0.09860547 0.08490765 0.06775833 0.00876506 0.01410718 0.20932552]\n",
      "+------------------+------+\n",
      "|        Classifier|Result|\n",
      "+------------------+------+\n",
      "|LogisticRegression| 88.72|\n",
      "|     GBTClassifier| 84.97|\n",
      "+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = 2\n",
    "\n",
    "#set up your results table\n",
    "columns = ['Classifier', 'Result']\n",
    "vals = [(\"Place Holder\",\"N/A\")]\n",
    "results = spark.createDataFrame(vals, columns)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    new_result = ClassTrainEval(classifier,features,classes,train,test)\n",
    "    results = results.union(new_result)\n",
    "results = results.where(\"Classifier!='Place Holder'\")\n",
    "results.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 FPR|                 TPR|\n",
      "+--------------------+--------------------+\n",
      "|                 0.0|                 0.0|\n",
      "|                 0.0|0.024390243902439025|\n",
      "|                 0.0| 0.04878048780487805|\n",
      "|                 0.0| 0.07317073170731707|\n",
      "|                 0.0|  0.0975609756097561|\n",
      "|                 0.0| 0.12195121951219512|\n",
      "|                 0.0| 0.14634146341463414|\n",
      "|                 0.0| 0.17073170731707318|\n",
      "|                 0.0|  0.1951219512195122|\n",
      "|                 0.0| 0.21951219512195122|\n",
      "|                 0.0| 0.24390243902439024|\n",
      "|0.008333333333333333| 0.25609756097560976|\n",
      "|0.016666666666666666|  0.2682926829268293|\n",
      "|0.016666666666666666|  0.2926829268292683|\n",
      "|0.016666666666666666|  0.3170731707317073|\n",
      "|0.016666666666666666| 0.34146341463414637|\n",
      "|0.016666666666666666| 0.36585365853658536|\n",
      "|0.016666666666666666|  0.3902439024390244|\n",
      "|0.016666666666666666|  0.4146341463414634|\n",
      "|0.016666666666666666| 0.43902439024390244|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "areaUnderROC: 0.930081300813008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression_074ab416fe8c"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification diagnostics for logistic regression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "crossval = CrossValidator(\n",
    "        estimator = lr,\n",
    "        estimatorParamMaps = paramGrid,\n",
    "        evaluator=BC_evaluator,\n",
    "        numFolds= 2)\n",
    "    \n",
    "lr_model = crossval.fit(train)\n",
    "best_model = lr_model.bestModel\n",
    "    \n",
    "trainingSummary = best_model.summary\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()\n",
    "\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
    "    .select('threshold').head()['threshold']\n",
    "classifier.setThreshold(bestThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
