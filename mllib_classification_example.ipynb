{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cce98b8f05b1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Classification</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f47b031aa30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"Classification\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# import boto3\n",
    "# import gzip\n",
    "# s3 = boto3.resource('s3')\n",
    "# PATH = \"s3://act-pyspark/949d9f4e6cfcc02b1c7fd2ef726be770/31988545f6a0cacac3cf4a5090e106d5/health/Core/Health/Assertive Community Treatment Outcomes/data.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.set_experiment(experiment_name = \"sd_ml\")\n",
    "\n",
    "# #set up client\n",
    "# from mlflow.tracking import MlflowClient\n",
    "# client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create a run\n",
    "\n",
    "# # Create a run and attach it to the experiment you just created\n",
    "# experiments = client.list_experiments() # returns a list of mlflow.entities.Experiment\n",
    "\n",
    "# experiment_name = \"sd-ml\"\n",
    "# def create_run(experiment_name):\n",
    "#     mlflow.set_experiment(experiment_name = experiment_name)\n",
    "#     for x in experiments:\n",
    "#         if experiment_name in x.name:\n",
    "# #             print(experiment_name)\n",
    "# #             print(x)\n",
    "#             experiment_index = experiments.index(x)\n",
    "#             run = client.create_run(experiments[experiment_index].experiment_id) # returns mlflow.entities.Run\n",
    "# #             print(run)\n",
    "#             return run\n",
    "\n",
    "# # Example run command\n",
    "# # run = create_run('Experiment-3')\n",
    "# # run = create_run(experiment_name)\n",
    "# # add tags to run\n",
    "# # add params and metrics to a run\n",
    "# # #terminate client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'sd-ml' does not exist. Creating a new experiment\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e5de999e88a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Add tag to a run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Algorithm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Gradient Boosted Tree\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Random Seed\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Train Perct\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "# # test the functionality here\n",
    "# run = create_run('sd-ml')\n",
    "\n",
    "# # Add tag to a run\n",
    "# client.set_tag(run.info.run_id, \"Algorithm\", \"Gradient Boosted Tree\")\n",
    "# client.set_tag(run.info.run_id,\"Random Seed\",999)\n",
    "# client.set_tag(run.info.run_id,\"Train Perct\",999)\n",
    "\n",
    "# # Add params and metrics to a run\n",
    "# client.log_param(run.info.run_id, \"Max Depth\", 999)\n",
    "# client.log_param(run.info.run_id, \"Max Bins\", 999)\n",
    "# client.log_metric(run.info.run_id, \"Accuracy\", 999)\n",
    "\n",
    "# # Terminate the client\n",
    "# client.set_terminated(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# obj = s3.Object(\"act-pyspark\", \n",
    "#                 \"949d9f4e6cfcc02b1c7fd2ef726be770/31988545f6a0cacac3cf4a5090e106d5/health/Core/Health/Assertive Community Treatment Outcomes/data.csv.gz\")\n",
    "# # with gzip.GzipFile(fileobj=obj.get()[\"Body\"]) as gzipfile:\n",
    "# #     content = gzipfile.read()\n",
    "# #     print(content)\n",
    "\n",
    "# act_df= spark.read.csv(PATH, inferSchema = True, header = True)\n",
    "# act_df.limit(6).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>resting_bps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fast_blood_sugar</th>\n",
       "      <th>rest_ecg_type</th>\n",
       "      <th>max_hr</th>\n",
       "      <th>exercise_angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope_type</th>\n",
       "      <th>colored_arteries</th>\n",
       "      <th>thal_type</th>\n",
       "      <th>heart_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  chest_pain_type  resting_bps   chol  fast_blood_sugar  \\\n",
       "0  63.0  1.0              1.0        145.0  233.0               1.0   \n",
       "1  67.0  1.0              4.0        160.0  286.0               0.0   \n",
       "2  67.0  1.0              4.0        120.0  229.0               0.0   \n",
       "3  37.0  1.0              3.0        130.0  250.0               0.0   \n",
       "4  41.0  0.0              2.0        130.0  204.0               0.0   \n",
       "5  56.0  1.0              2.0        120.0  236.0               0.0   \n",
       "\n",
       "   rest_ecg_type  max_hr  exercise_angina  oldpeak  slope_type  \\\n",
       "0            2.0   150.0              0.0      2.3         3.0   \n",
       "1            2.0   108.0              1.0      1.5         2.0   \n",
       "2            2.0   129.0              1.0      2.6         2.0   \n",
       "3            0.0   187.0              0.0      3.5         3.0   \n",
       "4            2.0   172.0              0.0      1.4         1.0   \n",
       "5            0.0   178.0              0.0      0.8         1.0   \n",
       "\n",
       "   colored_arteries  thal_type  heart_disease  \n",
       "0               0.0        6.0              0  \n",
       "1               3.0        3.0              2  \n",
       "2               2.0        7.0              1  \n",
       "3               0.0        3.0              0  \n",
       "4               0.0        3.0              0  \n",
       "5               0.0        3.0              0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"age\", FloatType(), True),\n",
    "    StructField(\"sex\", FloatType(), True),\n",
    "    StructField(\"chest_pain_type\", FloatType(), True),\n",
    "    StructField(\"resting_bps\", FloatType(), True),\n",
    "    StructField(\"chol\", FloatType(), True),\n",
    "    StructField(\"fast_blood_sugar\", FloatType(), True),\n",
    "    StructField(\"rest_ecg_type\", FloatType(), True),\n",
    "    StructField(\"max_hr\", FloatType(), True),\n",
    "    StructField(\"exercise_angina\", FloatType(), True),\n",
    "    StructField(\"oldpeak\", FloatType(), True),\n",
    "    StructField(\"slope_type\", FloatType(), True),\n",
    "    StructField(\"colored_arteries\", FloatType(), True),\n",
    "    StructField(\"thal_type\", FloatType(), True),\n",
    "    StructField(\"heart_disease\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "df = spark.read.csv(\"data/processed.cleveland.data\", schema = schema, header = False, nullValue='?')\n",
    "df.limit(6).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|heart_disease|count|\n",
      "+-------------+-----+\n",
      "|            1|   55|\n",
      "|            3|   35|\n",
      "|            4|   13|\n",
      "|            2|   36|\n",
      "|            0|  164|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('heart_disease').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  chest_pain_type  resting_bps  chol  fast_blood_sugar  \\\n",
      "0    0    0                0            0     0                 0   \n",
      "\n",
      "   rest_ecg_type  max_hr  exercise_angina  oldpeak  slope_type  \\\n",
      "0              0       0                0        0           0   \n",
      "\n",
      "   colored_arteries  thal_type  heart_disease  \n",
      "0                 4          2              0  \n"
     ]
    }
   ],
   "source": [
    "#check how much missing data there is\n",
    "data_agg = df.agg(*[count(when(isnull(c), c)).alias(c) for c in df.columns])\n",
    "print(data_agg.limit(8).toPandas())\n",
    "\n",
    "df_clean = df.na.drop()\n",
    "features = df.columns[:-1]\n",
    "label = 'heart_disease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_renamed = df.withColumn('label_str', df[label].cast(StringType()))\n",
    "labelIndexer = StringIndexer(inputCol=label, outputCol = 'label')\n",
    "indexed = labelIndexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|  1.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  1.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  0.0|\n",
      "|  1.0|\n",
      "|  0.0|\n",
      "|  1.0|\n",
      "|  0.0|\n",
      "|  1.0|\n",
      "|  0.0|\n",
      "|  1.0|\n",
      "|  0.0|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed.select('label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change string variables to numeric\n",
    "def to_numeric(indexed, features):\n",
    "    numeric_inputs = []\n",
    "    str_inputs = []\n",
    "    for column in features:\n",
    "        if str(indexed.schema[column].dataType) == 'StringType':\n",
    "            stringIndexer = StringIndexer(inputCol = column, outputCol = column+'_num')\n",
    "            indexed = stringIndexer.fit(indexed).transform(indexed)\n",
    "            new_col_name = column+'_num'\n",
    "            str_inputs.append(new_col_name)\n",
    "        else:\n",
    "            numeric_inputs.append(column)\n",
    "    return indexed, numeric_inputs, str_inputs\n",
    "\n",
    "indexed, numeric_inputs, str_inputs = to_numeric(indexed, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(skewness(A1)=-0.2563496093947895)]\n",
      "[Row(skewness(A2)=0.20601797730122015)]\n",
      "[Row(skewness(A3)=0.40260435804137373)]\n",
      "[Row(skewness(A4)=-0.04935088083712881)]\n",
      "[Row(skewness(A5)=-0.09879203126218447)]\n",
      "[Row(skewness(A6)=-0.3110969802658277)]\n",
      "[Row(skewness(A7)=-0.6285337660559676)]\n",
      "[Row(skewness(A8)=0.1637338005140266)]\n",
      "[Row(skewness(A9)=0.041754827339823934)]\n",
      "[Row(skewness(A10)=-0.3506177559444581)]\n",
      "[Row(skewness(Age_Mons)=-0.6341451203248881)]\n",
      "[Row(skewness(Qchat-10-Score)=-0.08006349388828135)]\n"
     ]
    }
   ],
   "source": [
    "def cap_and_transform__skewed_cols(indexed):\n",
    "    d = {}\n",
    "    for col in numeric_inputs:\n",
    "        # get values corresponding to bottom and top 1% of distribution\n",
    "        d[col] = indexed.approxQuantile(col, [0.01, 0.99], 0.25)\n",
    "\n",
    "        # transform col if skewed\n",
    "        skew = indexed.agg(f.skewness(indexed[col])).collect()\n",
    "        print(skew)\n",
    "        skew = skew[0][0]\n",
    "        if skew > 1:\n",
    "            #cap at top and bottom\n",
    "            indexed = indexed.withColumn(col, \\\n",
    "                                        log(when(df[col] < d[col][0], d[col][0])\\\n",
    "                                           .when(indexed[col] > d[col][1], d[col][1])\\\n",
    "                                           .otherwise(indexed[col]) + 1).alias(col))\n",
    "        elif skew < -1:\n",
    "            #cap at top and bottom\n",
    "            indexed = indexed.withColumn(col, \\\n",
    "                                        exp(when(df[col] < d[col][0], d[col][0])\\\n",
    "                                           .when(indexed[col] > d[col][1], d[col][1])\\\n",
    "                                           .otherwise(indexed[col]) + 1).alias(col))\n",
    "    return indexed\n",
    "\n",
    "indexed = cap_and_transform__skewed_cols(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what's minimum value in df?\n",
    "minimums = df.select([min(c).alias(c) for c in df.columns if c in numeric_inputs])\n",
    "min_array = minimums.select(array(numeric_inputs).alias(\"mins\"))\n",
    "df_minimum = min_array.select(array_min(min_array.mins)).collect()\n",
    "df_minimum[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  label\n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...    1.0\n",
       "1  (1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...    0.0\n",
       "2  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...    0.0\n",
       "3  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    0.0\n",
       "4  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    0.0\n",
       "5  [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...    0.0\n",
       "6  (1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, ...    0.0\n",
       "7  (0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...    0.0\n",
       "8  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...    1.0\n",
       "9  [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...    0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dense feature vector\n",
    "features_list = numeric_inputs + str_inputs\n",
    "assembler = VectorAssembler(inputCols = features_list, outputCol = 'features')\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"features_scaled\") \n",
    "pipeline = Pipeline(stages=[assembler, scaler])\n",
    "scalerModel = pipeline.fit(indexed)\n",
    "scaledData = scalerModel.transform(indexed).select('features', 'label')\n",
    "scaledData.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 721, test len: 333\n"
     ]
    }
   ],
   "source": [
    "train, test = scaledData.randomSplit([0.7, 0.3])\n",
    "print(f\"train len: {train.count()}, test len: {test.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_5b87d61772e0\n",
      "Area under ROC: 1.0\n",
      "GBTClassifier_f6620ded66d5\n",
      "Area under ROC: 1.0\n"
     ]
    }
   ],
   "source": [
    "classifiers = [LogisticRegression(), GBTClassifier()]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    print(classifier)\n",
    "    BC_evaluator = BinaryClassificationEvaluator() \n",
    "\n",
    "    paramGrid = (ParamGridBuilder().addGrid(classifier.maxIter, [10,15,20]).build())\n",
    "\n",
    "    crossval = CrossValidator(\n",
    "        estimator = classifier,\n",
    "        estimatorParamMaps = paramGrid,\n",
    "        evaluator=BC_evaluator,\n",
    "        numFolds= 2)\n",
    "\n",
    "    fitModel = crossval.fit(train)\n",
    "\n",
    "    best_model = fitModel.bestModel\n",
    "    \n",
    "# Linear regression:    \n",
    "#     print(f'Intercept: {str(best_model.interceptVector)}')\n",
    "#     print(f'Coefficients: {str(best_model.coefficientMatrix)}')\n",
    "\n",
    "    predictions = fitModel.transform(test) #fitModel automatically uses best model\n",
    "    area_under_roc = BC_evaluator.evaluate(predictions)\n",
    "    print(f\"Area under ROC: {area_under_roc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GBTClassificationModel' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-99a0cb8d2ae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#classification diagnostics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainingSummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainingSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GBTClassificationModel' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "#classification diagnostics\n",
    "trainingSummary = best_model.summary\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()\n",
    "\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
    "    .select('threshold').head()['threshold']\n",
    "classifier.setThreshold(bestThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
