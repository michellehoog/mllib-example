{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cce98b8f05b1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Classification</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fedd1d0bac0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"Classification\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, MinMaxScaler, OneHotEncoder, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>resting_bps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fast_blood_sugar</th>\n",
       "      <th>rest_ecg_type</th>\n",
       "      <th>max_hr</th>\n",
       "      <th>exercise_angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope_type</th>\n",
       "      <th>colored_arteries</th>\n",
       "      <th>thal_type</th>\n",
       "      <th>heart_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  chest_pain_type  resting_bps   chol  fast_blood_sugar  \\\n",
       "0  63.0  1.0              1.0        145.0  233.0               1.0   \n",
       "1  67.0  1.0              4.0        160.0  286.0               0.0   \n",
       "2  67.0  1.0              4.0        120.0  229.0               0.0   \n",
       "3  37.0  1.0              3.0        130.0  250.0               0.0   \n",
       "4  41.0  0.0              2.0        130.0  204.0               0.0   \n",
       "5  56.0  1.0              2.0        120.0  236.0               0.0   \n",
       "\n",
       "   rest_ecg_type  max_hr  exercise_angina  oldpeak  slope_type  \\\n",
       "0            2.0   150.0              0.0      2.3         3.0   \n",
       "1            2.0   108.0              1.0      1.5         2.0   \n",
       "2            2.0   129.0              1.0      2.6         2.0   \n",
       "3            0.0   187.0              0.0      3.5         3.0   \n",
       "4            2.0   172.0              0.0      1.4         1.0   \n",
       "5            0.0   178.0              0.0      0.8         1.0   \n",
       "\n",
       "   colored_arteries  thal_type  heart_disease  \n",
       "0               0.0        6.0              0  \n",
       "1               3.0        3.0              2  \n",
       "2               2.0        7.0              1  \n",
       "3               0.0        3.0              0  \n",
       "4               0.0        3.0              0  \n",
       "5               0.0        3.0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"age\", FloatType(), True),\n",
    "    StructField(\"sex\", FloatType(), True),\n",
    "    StructField(\"chest_pain_type\", FloatType(), True),\n",
    "    StructField(\"resting_bps\", FloatType(), True),\n",
    "    StructField(\"chol\", FloatType(), True),\n",
    "    StructField(\"fast_blood_sugar\", FloatType(), True),\n",
    "    StructField(\"rest_ecg_type\", FloatType(), True),\n",
    "    StructField(\"max_hr\", FloatType(), True),\n",
    "    StructField(\"exercise_angina\", FloatType(), True),\n",
    "    StructField(\"oldpeak\", FloatType(), True),\n",
    "    StructField(\"slope_type\", FloatType(), True),\n",
    "    StructField(\"colored_arteries\", FloatType(), True),\n",
    "    StructField(\"thal_type\", FloatType(), True),\n",
    "    StructField(\"heart_disease\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "df = spark.read.csv(\"data/processed.cleveland.data\", schema = schema, header = False, nullValue=\"?\")\n",
    "df.limit(6).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  summary                age                  sex     chest_pain_type  \\\n",
      "0   count                303                  303                 303   \n",
      "1    mean  54.43894389438944   0.6798679867986799  3.1584158415841586   \n",
      "2  stddev   9.03866244244675  0.46729882777012977  0.9601256119600138   \n",
      "3     min               29.0                  0.0                 1.0   \n",
      "4     max               77.0                  1.0                 4.0   \n",
      "\n",
      "          resting_bps                chol    fast_blood_sugar  \\\n",
      "0                 303                 303                 303   \n",
      "1  131.68976897689768  246.69306930693068  0.1485148514851485   \n",
      "2   17.59974772958769  51.776917542637065  0.3561978749279763   \n",
      "3                94.0               126.0                 0.0   \n",
      "4               200.0               564.0                 1.0   \n",
      "\n",
      "        rest_ecg_type              max_hr      exercise_angina  \\\n",
      "0                 303                 303                  303   \n",
      "1  0.9900990099009901   149.6072607260726  0.32673267326732675   \n",
      "2  0.9949712915251783  22.875003276980383  0.46979446452231644   \n",
      "3                 0.0                71.0                  0.0   \n",
      "4                 2.0               202.0                  1.0   \n",
      "\n",
      "              oldpeak          slope_type    colored_arteries  \\\n",
      "0                 303                 303                 299   \n",
      "1  1.0396039587977302  1.6006600660066006  0.6722408026755853   \n",
      "2  1.1610750102689422  0.6162261453459619   0.937438317724216   \n",
      "3                 0.0                 1.0                 0.0   \n",
      "4                 6.2                 3.0                 3.0   \n",
      "\n",
      "            thal_type       heart_disease  \n",
      "0                 301                 303  \n",
      "1    4.73421926910299  0.9372937293729373  \n",
      "2  1.9397057693786433  1.2285356879701044  \n",
      "3                 3.0                   0  \n",
      "4                 7.0                   4  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe().toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|heart_disease|count|\n",
      "+-------------+-----+\n",
      "|            1|   55|\n",
      "|            3|   35|\n",
      "|            4|   13|\n",
      "|            2|   36|\n",
      "|            0|  164|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"heart_disease\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  chest_pain_type  resting_bps  chol  fast_blood_sugar  \\\n",
      "0    0    0                0            0     0                 0   \n",
      "\n",
      "   rest_ecg_type  max_hr  exercise_angina  oldpeak  slope_type  \\\n",
      "0              0       0                0        0           0   \n",
      "\n",
      "   colored_arteries  thal_type  heart_disease  \n",
      "0                 4          2              0  \n"
     ]
    }
   ],
   "source": [
    "#check how much missing data there is\n",
    "dataAgg = df.agg(*[count(when(isnull(c), c)).alias(c) for c in df.columns])\n",
    "print(dataAgg.limit(8).toPandas())\n",
    "\n",
    "dfClean = df.na.drop()\n",
    "features = df.columns[:-1]\n",
    "label = \"heart_disease\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---------------+-----------+-----+----------------+-------------+------+---------------+-------+----------+----------------+---------+-------------+-----+\n",
      "| age|sex|chest_pain_type|resting_bps| chol|fast_blood_sugar|rest_ecg_type|max_hr|exercise_angina|oldpeak|slope_type|colored_arteries|thal_type|heart_disease|label|\n",
      "+----+---+---------------+-----------+-----+----------------+-------------+------+---------------+-------+----------+----------------+---------+-------------+-----+\n",
      "|63.0|1.0|            1.0|      145.0|233.0|             1.0|          2.0| 150.0|            0.0|    2.3|       3.0|             0.0|      6.0|            0|    0|\n",
      "|67.0|1.0|            4.0|      160.0|286.0|             0.0|          2.0| 108.0|            1.0|    1.5|       2.0|             3.0|      3.0|            2|    1|\n",
      "|67.0|1.0|            4.0|      120.0|229.0|             0.0|          2.0| 129.0|            1.0|    2.6|       2.0|             2.0|      7.0|            1|    1|\n",
      "|37.0|1.0|            3.0|      130.0|250.0|             0.0|          0.0| 187.0|            0.0|    3.5|       3.0|             0.0|      3.0|            0|    0|\n",
      "|41.0|0.0|            2.0|      130.0|204.0|             0.0|          2.0| 172.0|            0.0|    1.4|       1.0|             0.0|      3.0|            0|    0|\n",
      "|56.0|1.0|            2.0|      120.0|236.0|             0.0|          0.0| 178.0|            0.0|    0.8|       1.0|             0.0|      3.0|            0|    0|\n",
      "|62.0|0.0|            4.0|      140.0|268.0|             0.0|          2.0| 160.0|            0.0|    3.6|       3.0|             2.0|      3.0|            3|    1|\n",
      "|57.0|0.0|            4.0|      120.0|354.0|             0.0|          0.0| 163.0|            1.0|    0.6|       1.0|             0.0|      3.0|            0|    0|\n",
      "|63.0|1.0|            4.0|      130.0|254.0|             0.0|          2.0| 147.0|            0.0|    1.4|       2.0|             1.0|      7.0|            2|    1|\n",
      "|53.0|1.0|            4.0|      140.0|203.0|             1.0|          2.0| 155.0|            1.0|    3.1|       3.0|             0.0|      7.0|            1|    1|\n",
      "+----+---+---------------+-----------+-----+----------------+-------------+------+---------------+-------+----------+----------------+---------+-------------+-----+\n",
      "\n",
      "None\n",
      "['chest_pain_type', 'rest_ecg_type', 'slope_type', 'thal_type']\n"
     ]
    }
   ],
   "source": [
    "# change from multiclass to binary prediction\n",
    "dfBinary = dfClean.withColumn(\"label\", when(df.heart_disease == 0, 0).otherwise(1))\n",
    "print(dfBinary.limit(10).show())\n",
    "\n",
    "categoricalCols = [col for col in df.columns if \"type\" in col]\n",
    "print(categoricalCols)\n",
    "\n",
    "continuousCols = [f for f in features if \"type\" not in f]\n",
    "continuousCols.remove(\"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.7083333333333333, 0.4811320754716981, 0.244...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.7916666666666666, 0.6226415094339622, 0.365...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.7916666666666666, 0.24528301886792453, 0.23...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.16666666666666666, 0.33962264150943394, 0.2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.25, 0.33962264150943394, 0.1780821917808219...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.5625, 0.24528301886792453, 0.25114155251141...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.6875, 0.43396226415094336, 0.32420091324200...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.5833333333333333, 0.24528301886792453, 0.52...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.7083333333333333, 0.33962264150943394, 0.29...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.5, 0.43396226415094336, 0.17579908675799086...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  label\n",
       "0  [0.7083333333333333, 0.4811320754716981, 0.244...      0\n",
       "1  [0.7916666666666666, 0.6226415094339622, 0.365...      1\n",
       "2  [0.7916666666666666, 0.24528301886792453, 0.23...      1\n",
       "3  [0.16666666666666666, 0.33962264150943394, 0.2...      0\n",
       "4  [0.25, 0.33962264150943394, 0.1780821917808219...      0\n",
       "5  (0.5625, 0.24528301886792453, 0.25114155251141...      0\n",
       "6  [0.6875, 0.43396226415094336, 0.32420091324200...      1\n",
       "7  [0.5833333333333333, 0.24528301886792453, 0.52...      0\n",
       "8  [0.7083333333333333, 0.33962264150943394, 0.29...      1\n",
       "9  [0.5, 0.43396226415094336, 0.17579908675799086...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dense feature vector and scale\n",
    "featuresList = continuousCols + categoricalCols\n",
    "\n",
    "assembler = VectorAssembler(inputCols = featuresList, outputCol = \"features\")\n",
    "indexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexed\", maxCategories=5)\n",
    "scaler = MinMaxScaler(inputCol=\"indexed\", outputCol=\"features_scaled\")\n",
    "pipeline = Pipeline(stages=[assembler, indexer, scaler])\n",
    "scalerModel = pipeline.fit(dfBinary)\n",
    "scaledData = scalerModel.transform(dfBinary).select(\"features_scaled\", \"label\")\n",
    "scaledData = scaledData.withColumnRenamed(\"features_scaled\", \"features\")\n",
    "scaledData.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 201, test len: 96\n"
     ]
    }
   ],
   "source": [
    "trainPercent = 0.7\n",
    "seed = 1837\n",
    "train, test = scaledData.randomSplit([trainPercent, 1-trainPercent], seed = seed)\n",
    "print(f\"train len: {train.count()}, test len: {test.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add MLflow tracking\n",
    "\n",
    "* Create an experiment\n",
    "* Create a run / runs\n",
    "* Save tags, parameters, metrics and artifacts for a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "mlflow.set_experiment(experiment_name = \"sd_ml\")\n",
    "\n",
    "#set up client\n",
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a run and attach it to the experiment you just created\n",
    "experiments = client.list_experiments() \n",
    "\n",
    "experiment_name = \"sd_ml\"\n",
    "def create_run(experiment_name):\n",
    "    mlflow.set_experiment(experiment_name = experiment_name)\n",
    "    for x in experiments:\n",
    "        if experiment_name in x.name:\n",
    "            experiment_index = experiments.index(x)\n",
    "            run = client.create_run(experiments[experiment_index].experiment_id) # returns mlflow.entities.Run\n",
    "            return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just a demo of the functionality here\n",
    "run = create_run(experiment_name)\n",
    "\n",
    "# Add tag to a run\n",
    "client.set_tag(run.info.run_id, \"Algorithm\", \"Gradient Boosted Tree\")\n",
    "client.set_tag(run.info.run_id,\"Random Seed\", 999)\n",
    "client.set_tag(run.info.run_id,\"Train Perct\", 999)\n",
    "\n",
    "# Add params and metrics to a run\n",
    "client.log_param(run.info.run_id, \"Max Depth\", 999)\n",
    "client.log_param(run.info.run_id, \"Max Bins\", 999)\n",
    "client.log_metric(run.info.run_id, \"Accuracy\", 999)\n",
    "\n",
    "# Terminate the client\n",
    "client.set_terminated(run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Area under ROC: 0.8818342151675485\n",
      "GBTClassifier\n"
     ]
    }
   ],
   "source": [
    "def selectParameters(Mtype):\n",
    "    if Mtype == \"LogisticRegression\":\n",
    "            paramGrid = (ParamGridBuilder() \\\n",
    "                         .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "                         .addGrid(classifier.maxIter, [10, 15,20])\n",
    "                         .build())\n",
    "    if Mtype == \"RandomForestClassifier\":\n",
    "            paramGrid = (ParamGridBuilder() \\\n",
    "                         .addGrid(classifier.maxDepth, [2, 5, 10]) \\\n",
    "                         .addGrid(classifier.maxBins, [5, 10, 20]) \\\n",
    "                         .addGrid(classifier.numTrees, [5, 20])\n",
    "                         .build())\n",
    "\n",
    "    if Mtype == \"GBTClassifier\":\n",
    "        paramGrid = (ParamGridBuilder() \\\n",
    "                     .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "                     .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "                     .addGrid(classifier.maxIter, [10, 15]) \\\n",
    "                     .addGrid(classifier.stepSize, [0.1, 0.2, 0.3]) #learning rate\n",
    "                     .build())\n",
    "    return paramGrid\n",
    "\n",
    "def logParameters(best_model):\n",
    "    \n",
    "    paramMap = best_model.extractParamMap()\n",
    "\n",
    "    for key, val in paramMap.items():\n",
    "        if \"maxIter\" in str(key):\n",
    "            client.log_param(run.info.run_id, \"Max Iter\", val)\n",
    "        elif \"maxDepth\" in str(key):\n",
    "            client.log_param(run.info.run_id, \"Max Depth\", val)\n",
    "        elif \"maxBins\" in str(key):\n",
    "            client.log_param(run.info.run_id, \"Max Bins\", val)\n",
    "        elif \"regParam\" in str(key):\n",
    "            client.log_param(run.info.run_id, \"Reg Params\", val)\n",
    "            \n",
    "\n",
    "                \n",
    "classifiers = [LogisticRegression(), GBTClassifier(), RandomForestClassifier()]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    run = create_run(experiment_name)\n",
    "    client.set_tag(run.info.run_id, \"Algorithm\", classifier)\n",
    "    client.set_tag(run.info.run_id,\"Random Seed\",seed)\n",
    "    client.set_tag(run.info.run_id,\"Train Perct\",trainPercent)\n",
    "    \n",
    "    Mtype = type(classifier).__name__\n",
    "    print(Mtype)\n",
    "    BC_evaluator = BinaryClassificationEvaluator() \n",
    "    paramGrid = selectParameters(Mtype)\n",
    "\n",
    "    crossval = CrossValidator(\n",
    "        estimator = classifier,\n",
    "        estimatorParamMaps = paramGrid,\n",
    "        evaluator=BC_evaluator,\n",
    "        numFolds= 2)\n",
    "\n",
    "    fitModel = crossval.fit(train)\n",
    "\n",
    "    best_model = fitModel.bestModel\n",
    "    predictions = fitModel.transform(test) #fitModel automatically uses best model\n",
    "    area_under_roc = BC_evaluator.evaluate(predictions)\n",
    "    print(f\"Area under ROC: {area_under_roc}\")\n",
    "\n",
    "    client.log_metric(run.info.run_id, \"Area under ROC\", area_under_roc)\n",
    "    logParameters(best_model)\n",
    "    mlflow.spark.save_model(best_model, \"model_\"+str(Mtype))\n",
    "\n",
    "# Terminate the client\n",
    "client.set_terminated(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
